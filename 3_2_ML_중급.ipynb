{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "3-2. ML 중급.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junheeyoon/Big-Data-analyst-Study/blob/master/3_2_ML_%EC%A4%91%EA%B8%89.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWWTxuZ71u90"
      },
      "source": [
        "# Workflow\n",
        "- Load data\n",
        "- Data transformation\n",
        "- Pipeline을 이용한 모델 학습 및 예측\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4c985-41u90"
      },
      "source": [
        "# 1. Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7bBfcjX1u90"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7uVXun41u91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af1ab708-241c-4014-a5f8-0a9168dad8c8"
      },
      "source": [
        "cats = ['alt.atheism', 'sci.space']\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', categories=cats)\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', categories=cats)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc0DyVUQ1u91"
      },
      "source": [
        "X_train = newsgroups_train.data\n",
        "X_test = newsgroups_test.data\n",
        "y_train = newsgroups_train.target\n",
        "y_test = newsgroups_test.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mRnMy7i1u91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de017b0f-04a7-421a-a231-55c2b39df953"
      },
      "source": [
        "len(X_train),\\\n",
        "len(X_test),\\\n",
        "y_train.shape,\\\n",
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1073, 713, (1073,), (713,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0uUKKKl1u92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf40c7eb-a853-411e-ba49-fa3a7095b063"
      },
      "source": [
        "print(X_train[0])\n",
        "print(\"[Label: {}]\".format(y_train[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From: bil@okcforum.osrhe.edu (Bill Conner)\n",
            "Subject: Re: Not the Omni!\n",
            "Nntp-Posting-Host: okcforum.osrhe.edu\n",
            "Organization: Okcforum Unix Users Group\n",
            "X-Newsreader: TIN [version 1.1 PL6]\n",
            "Lines: 18\n",
            "\n",
            "Charley Wingate (mangoe@cs.umd.edu) wrote:\n",
            ": \n",
            ": >> Please enlighten me.  How is omnipotence contradictory?\n",
            ": \n",
            ": >By definition, all that can occur in the universe is governed by the rules\n",
            ": >of nature. Thus god cannot break them. Anything that god does must be allowed\n",
            ": >in the rules somewhere. Therefore, omnipotence CANNOT exist! It contradicts\n",
            ": >the rules of nature.\n",
            ": \n",
            ": Obviously, an omnipotent god can change the rules.\n",
            "\n",
            "When you say, \"By definition\", what exactly is being defined;\n",
            "certainly not omnipotence. You seem to be saying that the \"rules of\n",
            "nature\" are pre-existant somehow, that they not only define nature but\n",
            "actually cause it. If that's what you mean I'd like to hear your\n",
            "further thoughts on the question.\n",
            "\n",
            "Bill\n",
            "\n",
            "[Label: 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuDg16Xe1u92"
      },
      "source": [
        "# 2. Data Transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cBTKQxY1u92"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ae_hNc8k1u92"
      },
      "source": [
        "vect = CountVectorizer()\n",
        "tfidf = TfidfTransformer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6iUkoek1u92"
      },
      "source": [
        "# 3. Pipeline을 이용한 학습 구성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecFBLi911u92"
      },
      "source": [
        "### 1) 필요한 모델 Estimator 인스턴트화(선언)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2yPmjek1u92"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import LinearSVC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrE-p2B71u92"
      },
      "source": [
        "clf = LinearSVC()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_BfG2BY1u92"
      },
      "source": [
        "## 2) Pipeline\n",
        "Pipeline은 모델의 학습 과정에 포함되는 몇가지의 단계를 단순화해주는 기능이다. 이를 통해, 최종 모델을 위한 재학습이나 Cross-validation 등을 위해 학습을 반복하는 상황에서, Pipeline을 이용하면 이를 쉽고 간편하게 진행할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYCK6fzT1u92"
      },
      "source": [
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TWxT1VE1u92"
      },
      "source": [
        "pipeline = Pipeline([\n",
        "    ('vect',vect),\n",
        "    ('tfidf',tfidf),\n",
        "    ('clf',clf)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBUEA-B61u92"
      },
      "source": [
        "## 3) Test set 검증"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJ-PwGZNibUo",
        "outputId": "0d0cd6d4-6566-4386-bb9d-5ac9604ceaac"
      },
      "source": [
        "pipeline.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=0.9,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('tfidf',\n",
              "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
              "                                  sublinear_tf=False, use_idf=True)),\n",
              "                ('clf',\n",
              "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
              "                           fit_intercept=True, intercept_scaling=1,\n",
              "                           loss='squared_hinge', max_iter=1000,\n",
              "                           multi_class='ovr', penalty='l2', random_state=None,\n",
              "                           tol=0.0001, verbose=0))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XNcNr4Fifr4",
        "outputId": "fa72030f-a50e-467a-afdf-ed83468f05f0"
      },
      "source": [
        "pipeline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=0.9,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('tfidf',\n",
              "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
              "                                  sublinear_tf=False, use_idf=True)),\n",
              "                ('clf',\n",
              "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
              "                           fit_intercept=True, intercept_scaling=1,\n",
              "                           loss='squared_hinge', max_iter=1000,\n",
              "                           multi_class='ovr', penalty='l2', random_state=None,\n",
              "                           tol=0.0001, verbose=0))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQaSrlZbi8Nz",
        "outputId": "af500cfa-57ef-4e11-8955-8c031d850363"
      },
      "source": [
        "y_preds = pipeline.predict(X_test)\n",
        "y_preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
              "       0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
              "       1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
              "       0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
              "       1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "       0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
              "       0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
              "       0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
              "       1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1,\n",
              "       1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
              "       0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
              "       0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0,\n",
              "       1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
              "       0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "       0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
              "       1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
              "       1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "       0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "       0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
              "       1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
              "       1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
              "       0, 1, 1, 0, 0, 0, 1, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wClmQHPT1u92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a1ed451-399d-461a-af70-fec3a08b9ffe"
      },
      "source": [
        "# now train and predict test instances\n",
        "\n",
        "\n",
        "# calculate f1\n",
        "f1_score(y_test, y_preds, average='micro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9761570827489481"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6EqwlGT1u92"
      },
      "source": [
        "## 4) Cross validation\n",
        "CV를 위해서는 데이터의 변환, 학습, 평가를 k번 만큼 진행해야 한다. 따라서 위에서 만든 pipeline을 이용하여 CV를 사용한다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Xol25Wz1u92"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ID5HeJAx1u92"
      },
      "source": [
        "X = np.append(X_train, X_test)\n",
        "y = np.append(y_train, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfkj3X4j1u92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "933a8a15-20cc-4dd4-cf85-1629e39e0ceb"
      },
      "source": [
        "scores = cross_val_score(pipeline,X,y,cv=5,scoring='f1_micro')\n",
        "\n",
        "scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.99162011, 0.99159664, 1.        , 0.9859944 , 0.99439776])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsTT3JLd1u92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b88a1eda-067a-4ba7-bb0c-b5a229e3ffed"
      },
      "source": [
        "scores.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9927217814500102"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bekbgaP91u92"
      },
      "source": [
        "## 5) Grid search\n",
        "모델 최적화를 위한 파라미터 탐색에 사용되는 Grid Search 방법을 적용하기 위해서도 반복적인 학습이 필요하다. Grid Search를 통한 파라미터 최적화도 pipeline을 통해 쉽게 구성할 수 있다 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBTE6ggQ1u92"
      },
      "source": [
        "파라미터 최적화를 위해서, 각 파이프라인을 구성하는 함수들에서 최적화 하고싶은 파라미터들의 범위를 설정한다|"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmMPGd0f1u93"
      },
      "source": [
        "param_grid = [\n",
        "    {\n",
        "        'vect__max_df':[0.8,0.9,1.0],\n",
        "        'clf__penalty':['l2'],\n",
        "        'clf__dual':[True,False]\n",
        "    },\n",
        "    {\n",
        "        'vect__max_df':[0.8,0.9,1.0],\n",
        "        'clf__penalty':['l1'],\n",
        "        'clf__dual': [False]\n",
        "    }\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExtCFOaW1u93"
      },
      "source": [
        "GridSearchCV는 Cross validation 에서 각 k마다 Grid Search를 통해 파라미터를 최적화하는 방법이다 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lNWc8MC1u93"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb2dCGpb1u93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c5bbd34-c846-42a0-e9db-ccedc970ad5b"
      },
      "source": [
        "grid = GridSearchCV(pipeline, cv=5, param_grid=param_grid, scoring='f1_micro')\n",
        "grid.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('vect',\n",
              "                                        CountVectorizer(analyzer='word',\n",
              "                                                        binary=False,\n",
              "                                                        decode_error='strict',\n",
              "                                                        dtype=<class 'numpy.int64'>,\n",
              "                                                        encoding='utf-8',\n",
              "                                                        input='content',\n",
              "                                                        lowercase=True,\n",
              "                                                        max_df=1.0,\n",
              "                                                        max_features=None,\n",
              "                                                        min_df=1,\n",
              "                                                        ngram_range=(1, 1),\n",
              "                                                        preprocessor=None,\n",
              "                                                        stop_words=None,\n",
              "                                                        strip_accents=None,\n",
              "                                                        token_pattern='(?u)...\n",
              "                                                  penalty='l2',\n",
              "                                                  random_state=None, tol=0.0001,\n",
              "                                                  verbose=0))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'clf__dual': [True, False], 'clf__penalty': ['l2'],\n",
              "                          'vect__max_df': [0.8, 0.9, 1.0]},\n",
              "                         {'clf__dual': [False], 'clf__penalty': ['l1'],\n",
              "                          'vect__max_df': [0.8, 0.9, 1.0]}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='f1_micro', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrNBSHgV1u93"
      },
      "source": [
        "최적 파라미터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1saqV8291u93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11064243-7f23-4804-ba19-f22313bdc1d3"
      },
      "source": [
        "print(\"Best: %f using %s\" % (grid.best_score_, grid.best_params_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.994414 using {'clf__dual': True, 'clf__penalty': 'l2', 'vect__max_df': 0.8}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wU8BLBKC1u93"
      },
      "source": [
        "전체 실험결과 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ledF-sAT1u93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbcd7eea-b903-42cd-92b5-1aa75ef609be"
      },
      "source": [
        "means = grid.cv_results_['mean_test_score']\n",
        "stds = grid.cv_results_['std_test_score']\n",
        "params = grid.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.994414 (0.003479) with: {'clf__dual': True, 'clf__penalty': 'l2', 'vect__max_df': 0.8}\n",
            "0.994414 (0.003479) with: {'clf__dual': True, 'clf__penalty': 'l2', 'vect__max_df': 0.9}\n",
            "0.993484 (0.004742) with: {'clf__dual': True, 'clf__penalty': 'l2', 'vect__max_df': 1.0}\n",
            "0.994414 (0.003479) with: {'clf__dual': False, 'clf__penalty': 'l2', 'vect__max_df': 0.8}\n",
            "0.994414 (0.003479) with: {'clf__dual': False, 'clf__penalty': 'l2', 'vect__max_df': 0.9}\n",
            "0.993484 (0.004742) with: {'clf__dual': False, 'clf__penalty': 'l2', 'vect__max_df': 1.0}\n",
            "0.972984 (0.009003) with: {'clf__dual': False, 'clf__penalty': 'l1', 'vect__max_df': 0.8}\n",
            "0.972984 (0.011150) with: {'clf__dual': False, 'clf__penalty': 'l1', 'vect__max_df': 0.9}\n",
            "0.974853 (0.011596) with: {'clf__dual': False, 'clf__penalty': 'l1', 'vect__max_df': 1.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtk9lBDL1u93"
      },
      "source": [
        "최적 파라미터를 통한 Test accuracy. 파라미터를 최적화하지 않았을 때보다 근소하게 accuracy가 증가했다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtErSLjO1u93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75f68583-0f6d-4042-f8a1-a85f43942df3"
      },
      "source": [
        "# now train and predict test instances\n",
        "# using the best configs\n",
        "pipeline.set_params(clf__penalty='l2',vect__max_df=0.9,clf__dual=True)\n",
        "pipeline.fit(X_train,y_train)\n",
        "y_preds = pipeline.predict(X_test)\n",
        "\n",
        "# calculate f1\n",
        "f1_score(y_test, y_preds, average='micro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9761570827489481"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nq1YMKzG1u93"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}